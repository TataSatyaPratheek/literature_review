"""Classical target neural network (parameterized by quantum output)."""
import torch
import torch.nn as nn
import torch.nn.functional as F

class ClassicalTargetCNN(nn.Module):
    """
    Classical CNN for MNIST/CIFAR-10 classification.
    Parameters are set by the quantum-mapping pipeline.
    """
    
    def __init__(self, config):
        """Initialize classical CNN architecture."""
        super().__init__()
        self.config = config
        
        # Define architecture (parameters will be set externally)
        arch = config.classical_architecture
        
        self.conv1 = nn.Conv2d(
            arch['conv1']['in_channels'],
            arch['conv1']['out_channels'],
            arch['conv1']['kernel_size']
        )
        self.conv2 = nn.Conv2d(
            arch['conv2']['in_channels'],
            arch['conv2']['out_channels'],
            arch['conv2']['kernel_size']
        )
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(
            arch['fc1']['in_features'],
            arch['fc1']['out_features']
        )
        self.fc2 = nn.Linear(
            arch['fc2']['in_features'],
            arch['fc2']['out_features']
        )
        
    def forward(self, x):
        """Forward pass through the network."""
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x
    
    def set_parameters_from_vector(self, theta):
        """
        Set all network parameters from a flat vector.
        
        Args:
            theta: Tensor containing all parameters (generated by quantum+mapping)
        """
        offset = 0
        for param in self.parameters():
            numel = param.numel()
            if offset + numel > theta.numel():
                raise RuntimeError(
                    f"Parameter vector too small. Need {offset + numel}, got {theta.numel()}"
                )
            param.data = theta[offset:offset + numel].view(param.shape).clone()
            offset += numel
        
        if offset != theta.numel():
            print(f"Warning: Used {offset} parameters out of {theta.numel()} available")
    
    def count_parameters(self):
        """Count total number of parameters."""
        return sum(p.numel() for p in self.parameters())
